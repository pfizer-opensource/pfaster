# -*- coding: utf-8 -*-
"""
Python 3.10.6
26 March 2020
"""

import bisect
import pickle

from Bio import SeqIO
from Bio.SeqIO.QualityIO import FastqGeneralIterator
import mmh3
import screed


class MinHash:

    def __init__(self, k = 70, s = 1000, seed = 42):
        self.s = s
        self.k = k
        self.seed = seed

    # convert k-mer to its canonical sequence
    def get_canon_seq(self, kmer):
        '''
        kmer: str - DNA sequence k-mer
        '''
        # obtain reverse complement
        rc = screed.rc(kmer)
        # choose lexicographically smaller sequence
        if rc < kmer:
            return rc
        else:
            return kmer

    # obtain hash of a k-mer; runs murmurhash3
    def hash_kmer(self, kmer, seed = 42):
        canon_kmer = self.get_canon_seq(kmer)
        if self.k <= 32:
            hash_val = mmh3.hash64(canon_kmer, seed)[0]
        elif self.k <= 64:
            hash_val = mmh3.hash128(canon_kmer, seed)
        else:
            hash_val = mmh3.hash128(canon_kmer, seed, signed = True)
        return hash_val


    def mash(self, seq):

        '''
        seq: str - sequence to k-mer hash
        k: int - k-mer size
        s: int - maximum hashes to save
        '''

        hash_dict = {} # dictionary of saved hash values
        hash_list = [] # sorted list of min hash values
        # builds a sorted array of minimum s hash values
        i = 0
        while i <= len(seq)- self.k:
            kmer = seq[i:(i+ self.k - 1)].upper() # converts to upper to ignore strand
            canon_kmer = self.get_canon_seq(kmer)
            k_hashed = self.hash_kmer(canon_kmer)

            if k_hashed in hash_dict:
                 # count implementation for potential future use with raw reads
                hash_dict[k_hashed] += 1

            else:
                hash_dict[k_hashed] = 1
                bisect.insort(hash_list, k_hashed)

                # remove the largest value if above s hashes
                if len(hash_dict) > self.s:
                    hash_max = hash_list[-1]
                    del hash_dict[hash_max]
                    del hash_list[-1]

            i += 1

        return hash_list

    # k-mer hash reference database and save
    def hash_database(self, ref_file):
        '''
        k: int - k-mer size
        '''
        ref_hashes = {}
        ref_sequences = SeqIO.parse(open(ref_file),'fasta')
        for fasta in ref_sequences:
            ref_hashes[fasta.id] = self.mash(seq = str(fasta.seq))

        return ref_hashes

    # pickle dump database
    def write_database(self, hash_db, outfile):
        '''
        hash_db: dict - k-mer hash database
        outfile: str - path to output pickle file
        '''
        with open(outfile, 'wb') as pkl_out:
            pickle.dump(hash_db, pkl_out)


class MashScreen:

    def __init__(self, db_file, k = 70, seed = 42):
        self.k = k
        self.seed = seed
        self.minhash_db = self.load_database(db_file)

    def load_database(self, pkl):
        '''
        pkl: str - name of input reference sketch file
        '''
        with open(pkl, 'rb') as inf:
            db = pickle.load(inf)
        return db

    # transpose reference sketch db into screen db
    def screen_convert_db(self, minhash_db):
        '''
        minhash_db: dict - reference sketches
        '''
        screen_dict = {}

        for key in minhash_db:
            for hash_val in minhash_db[key]:
                if hash_val in screen_dict:
                    screen_dict[hash_val].append(key)
                else:
                    screen_dict[hash_val] = [key]
        return screen_dict

    # initiate table to count occurence of hashes in database
    def init_stream_dict(self, screen_db):
        '''
        screen_db: dict - transposition generated by screen_convert_db
        '''
        count_dict = {key:0 for key in screen_db.keys()}
        return count_dict

    # helper to mash screen on fasta format
    def screen_fasta(self, query_file):
        mh = MinHash(k = self.k, seed = self.seed)
        sequences = SeqIO.parse(open(query_file), 'fasta')
        for contig in sequences:
            seq = str(contig.seq).strip()
            i = 0
            while i <= len(seq)- self.k:
                kmer = seq[i:(i + self.k - 1)].upper()
                k_hashed = mh.hash_kmer(kmer)
                if k_hashed in self.hash_counts:
                    self.hash_counts[k_hashed] += 1
                i += 1

    # count number of matched hashes per reference genome
    def count_matches(self):
        '''
        see mash_screen(...) for input formats
        '''
        screen_db = self.screen_convert_db(self.minhash_db)

        self.ref_counts = {key:0 for key in self.minhash_db}
        for k, refs in screen_db.items():
            if self.hash_counts[k]:
                for ref in refs:
                    self.ref_counts[ref] += 1

    # perform mash screen using the streaming method
    def screen(self, query_file):
        '''
        minhash_db: dict - minhash sketches of reference sequences
        query_file: fastq file of contigs to screen
        '''
        # transpose sketches to streaming database
        screen_db = self.screen_convert_db(self.minhash_db)
        # intitiate hits to each reference sequence
        self.hash_counts = self.init_stream_dict(screen_db)
        # perform Mash screen
        self.screen_fasta(query_file)
        # count matches
        self.count_matches()
